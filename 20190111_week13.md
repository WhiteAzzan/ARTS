# Algorithm

#### 392. 判断子序列

给定字符串 s 和 t ，判断 s 是否为 t 的子序列。

你可以认为 s 和 t 中仅包含英文小写字母。字符串 t 可能会很长（长度 ~= 500,000），而 s 是个短字符串（长度 <=100）。

字符串的一个子序列是原始字符串删除一些（也可以不删除）字符而不改变剩余字符相对位置形成的新字符串。（例如，"ace"是"abcde"的一个子序列，而"aec"不是）。

示例 1:
s = "abc", t = "ahbgdc"

返回 true.

示例 2:
s = "axc", t = "ahbgdc"

返回 false.

后续挑战 :

如果有大量输入的 S，称作S1, S2, ... , Sk 其中 k >= 10亿，你需要依次检查它们是否为 T 的子序列。在这种情况下，你会怎样改变代码？

**思路：**

这里又用到了双指针：

s: a  b  c

   |
   
   s_p


t: a  h  b  g  c  k

   |
   
  t_p
  
  
这里我们不断移动t_p指针，看t_p指向的元素是否和s_p指向的相等，如果不相等的话继续移动t_p，如果相等的话也一并移动s_p，直到t_p到达了t的边界。在这期间，
如果s_p已经到达了s的边界的话，就直接返回True。若整个循环结束，就是t遍历完都没有返回true的话，就说明不存在，返回false

代码：
```
class Solution:
    def isSubsequence(self, s, t):
        if s == None or t == None:  #判断字符串的是否为空
        return False
        
        len_s = len(s)    #长度获取
        len_t = len(t)    
        if len_t < len_s:   #判断长度的真实性
            return False
        if len_s == 0:
            return True
        j=0
        for i in range(len_t):    #若对于t串来讲，若和s相等，就继续移动
            if s[j] == t[i]:
                j+=1              
            if j == len_s:    #最终如果移动的次数和s的长度相等就返回True
                return True
        return False
```

python内置了find()函数可以快速定位字符的位置
```
class Solution:
    def isSubsequence(self, s, t):
        """
        :type s: str
        :type t: str
        :rtype: bool
        """
        for seq_s in s:
            s_index = t.find(seq_s)
            if s_index == -1:
                return False
            if s_index == len(t) - 1: #如果找到的匹配的s达到了t的长度
                t = str()             #字符串长度赋给t
            else:                   
                t = t[s_index+1:]       #若还没匹配完，从下一个开始继续
        return True
```

#### **爬楼梯**
假设你正在爬楼梯。需要 n 阶你才能到达楼顶。

每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？

注意：给定 n 是一个正整数。

示例 1：

输入： 2
输出： 2
解释： 有两种方法可以爬到楼顶。
1.  1 阶 + 1 阶
2.  2 阶
示例 2：

输入： 3
输出： 3
解释： 有三种方法可以爬到楼顶。
3.  1 阶 + 1 阶 + 1 阶
4.  1 阶 + 2 阶
5.  2 阶 + 1 阶

**思路：**
爬楼梯算是DP的经典题目，递归+记忆化，也就是递推，我们需要定义号状态，还有状态的转移方程。最后爬的步数还是得看之前的，即依赖之前的步骤。

1.反着考虑，有几种方案到第i阶楼梯，答案是2种：

第i-1阶楼梯经过一步
第i-2阶楼梯经过两步
假设count(i)表示到第i阶楼梯方案的个数，则count(i) = count(i-1) + count(i-2) 
第一阶是1种，第二阶是2种。代码如下：

```
class Solution:
    def climbStairs(self, n):
        """
        :type n: int
        :rtype: int
        """
        count = [1,2]   #一次就只能走这两步
        for i in range(2,n):
            count.append(count[i-1]+count[i-2])	#不停地把后面的台阶的结束放到count里面
        return count[n-1]
```
但是太慢了。。。这里起码O(n!)

2.我们想到可以转化为fibonaqi问题。假设一共有10阶楼梯，每步可以爬1步或者2步，那么你爬到10阶一共有两种方法，从8阶爬2步，或从9阶爬1步，那么爬到9阶也是这样，那这就是一共基本的斐波那契数列。
dp[i] = dp[i-1] + dp[i-2]
i-1的时候跳一步可以到达i
i-2的时候跳一步是i-1，这个变成dp[i-1]的子问题了,直接跳两步可以到达i

```
class Solution:
    def climbStairs(self, n):
        """
        :type n: int
        :rtype: int
        """
        dp = [1 for i in range(n+1)]   #状态的定义
        for i in range(2,n+1):
            dp[i] = dp[i-1]+dp[i-2]	#状态转移方程
        return dp[n]
```
这里应该是O(n^2)
3.还有一种更快速的，列表初始化好，然后再用fibonaqi数列转移方程。

```
class Solution:
    def climbStairs(self, n):
        """
        :type n: int
        :rtype: int
        """
        condition = [0]*(n+1)		#牛逼的初始化列表
        condition[0] = 1
        condition[1] = 1
        for i in range(2,n+1):
            condition[i] = condition[i-1]+condition[i-2]   #依然还是状态转移fibonaqo
        return condition[n]
```
这里列表初始化只用来O(1)，最后复杂度为O(n)

### Review

物体检测（Object Detection）的任务是找出图像或视频中的感兴趣目标，同时实现输出检测目标的位置和类别，是机器视觉领域的核心问题之一，学术界已有将近二十年的研究历史。随着深度学习技术的火热发展，目标检测算法也从基于手工特征的传统算法转向了基于深度神经网络的检测技术。从最初 2013 年提出的 R-CNN、OverFeat，到后面的 Fast/Faster R-CNN、SSD、YOLO 系列，以及Mask R-CNN、RefineDet、RFBNet等.短短不到五年时间，基于深度学习的目标检测技术，在网络结构上，从 two stage 到 one stage，从 bottom-up only 到 Top-Down，从 single scale network 到 feature pyramid network，从面向 PC 端到面向移动端，都涌现出许多好的算法技术，这些算法在开放目标检测数据集上的检测效果和性能都很出色。

![](http://www.sigai.cn/upload/image/20181029/1540806982395992.png)

介绍在目标检测中使用的检测框去重，包括NMS，Soft-NMS,Softer-NMS,以及Relation Netwrok，ConvNMS，NMS Network，Yes-Net等，详细讲述NMS算法的演变和最新进展

##### 1、传统NMS算法

**1.1 NMS介绍**

在目标检测中，常会利用非极大值抑制算法(NMS，non maximum suppression)对生成的大量候选框进行后处理，去除冗余的候选框，得到最佳检测框，以加快目标检测的效率。其本质思想是其思想是搜素局部最大值，抑制非极大值。非极大值抑制，在计算机视觉任务中得到了广泛的应用，例如边缘检测、人脸检测、目标检测（DPM，YOLO，SSD，Faster R-CNN）等。即如图 2所示实现效果，消除多余的候选框，找到最佳的bbox。

![](http://www.sigai.cn/upload/image/20181029/1540806997691194.png)

以图 2为例，每个选出来的Bounding Box检测框（既BBox）用（x,y,h,w, confidence score，Pdog,Pcat）表示，confidence  score表示background和foreground的置信度得分，取值范围[0,1]。Pdog,Pcat分布代表类别是狗和猫的概率。如果是100类的目标检测模型，BBox输出向量为5+100=105。

值得注意的是，RCNN有一句话的NMS介绍，Fast-RCNN无任何NMS的解释，Faster有大量篇幅对NMS的效果分析。

**1.2 NMS算法过程**

NMS主要就是通过迭代的形式，不断的以最大得分的框去与其他框做IoU操作，并过滤那些IoU较大（即交集较大）的框。如图 3图 4所示NMS的计算过程。

1、根据候选框的类别分类概率做排序，假如有4个 BBox ，其置信度A>B>C>D。



2、先标记最大概率矩形框A是算法要保留的BBox；



3、从最大概率矩形框A开始，分别判断ABC与D的重叠度IOU（两框的交并比）是否大于某个设定的阈值(0.5)，假设D与A的重叠度超过阈值，那么就舍弃D；



4、从剩下的矩形框BC中，选择概率最大的B，标记为保留，然后判读C与B的重叠度，扔掉重叠度超过设定阈值的矩形框；



5、一直重复进行，标记完所有要保留下来的矩形框。

![](http://www.sigai.cn/upload/image/20181029/1540807008906001.png)

![](http://www.sigai.cn/upload/image/20181029/1540807024441879.png)

如果是two stage算法，通常在选出BBox有BBox位置(x,y,h,w)和confidence score，没有类别的概率。因为程序是生成BBox，再将选择的BBox的feature map做rescale (一般用ROI pooling)，然后再用分类器分类。NMS一般只能在CPU计算，这也是two stage相对耗时的原因。



但如果是one stage作法，BBox有位置信息(x,y,h,w)、confidence score，以及类别概率，相对于two stage少了后面的rescale和分类程序，所以计算量相对少。



**1.3 优缺点分析**

NMS缺点：

1、NMS算法中的最大问题就是它将相邻检测框的分数均强制归零(既将重叠部分大于重叠阈值Nt的检测框移除)。在这种情况下，如果一个真实物体在重叠区域出现，则将导致对该物体的检测失败并降低了算法的平均检测率（average precision, AP）。



2、NMS的阈值也不太容易确定，设置过小会出现误删，设置过高又容易增大误检。



3、NMS一般只能使用CPU计算，无法使用GPU计算。

### Tips

**面试当中的技巧**

项目经历和项目中遇到的问题

你遇到的印象最深的bug是什么？

遇到的最大的挑战？

犯过的错误？

遭遇的失败

最享受的工作内容

遇到冲突的处理方式

做的最与众不同的事情

**准备好问面试官的问题**

整个小组的大概运行模式是什么样的？

整个项目的后续规划是什么样的？

这个产品中的某个问题是怎么解决的？

为什么会选择这个技术？标准是什么？

我对某个技术很感兴趣，在你们组中我会有什么样的机会深入学习这个技术？

### Share

前面讲到项目经历一方面可以用于匹配技能，另一方面也可以通过你在项目中解决的问题来展示你的能力。可以按照下面的步骤介绍项目：

为什么做这个项目；

项目有哪些功能；

你在项目中担任的角色；

碰到了哪些问题；

使用什么方式去解决问题的；

解决效果是怎样，和别人相比有什么优势。

不要用太过主观的语言，而是用数据等客观事实。比如介绍碰到的问题时，不要用“非常难解决”等词语，而是用“并发用户数达到XXX导致响应时间增加到XXX”等数据。

也不要堆叠无意义的技术名词。




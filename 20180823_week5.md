# ARTS
algorithm, review, tips, share

## Algorithm
###
## Review
![如何阅读科研论文](https://violentmetaphors.com/2013/08/25/how-to-read-and-understand-a-scientific-paper-2/)
再次学习一篇如何阅读科学性论文的文章
1. Begin by reading the introduction, not the abstract.
首先阅读的是介绍，而不是摘要。阅读标题和摘要可以使我们做出看不看文章的决定，但是如果你确定了要看一篇文章的话，直接看摘要也许会影响你最结果的判断。
所以最后看摘要也是可以的。

2. Identify the BIG QUESTION.
关键点不是这篇文章是什么，而是在这个领域中要解决什么样的一个问题。让你知道为什么要进行这样一个研究。

3.Summarize the background in five sentences or less.
前人在这个领域解决了哪些问题，有什么局限性？作者接下来要解决什么样的问题？

4. Identify the SPECIFIC QUESTION(S)
明确作者要解决的具体问题是什么？一个？多个？假设是什么？记录下来。

5. Identify the approach
明确作者要用什么方法去解决上述的问题。

6. Now read the methods section. Draw a diagram for each experiment, showing exactly what the authors did.
阅读方法的部分，绘制每个实验的图标，要准确地知道作者的所做所为，从字面上描述，尽可能详细的细节，以充分了解工作。

7. Read the results section. Write one or more paragraphs to summarize the results for each experiment, each figure, and each table. Don’t yet try to decide what the results mean, just write down what they are.
阅读结果部分，写下一段甚至多段来总结每一个实验，图表和表格的结果，不要死扣结果是什么，只要写下来就好。

8. Do the results answer the SPECIFIC QUESTION(S)? What do you think they mean?
文章的结果是否回答了具体的问题，你认为结果的意思是什么？作者的解释很可能会改变你最这篇文章的理解。

9. Read the conclusion/discussion/Interpretation section.
阅读结论，讨论以及解释部分。作者认为得到的结果是什么，你同意吗？你能用什么方式去解释？作者的文章有什么缺陷？你发现了什么缺陷?

10. Now, go back to the beginning and read the abstract.
现在你可以回过头来去看摘要了，看是否和作者的整体结果匹配。能够解释的通顺吗？

11. FINAL STEP: (Don’t neglect doing this) What do other researchers say about this paper?
最后一步，让其他同领域的专家看看这篇文章是否是好的。

## Tips
python中copy模块中copy与deepcopy之间的区别

```
>>> import copy
>>> origin = [1, 2, [3, 4]]
#origin 里边有三个元素：1， 2，[3, 4]
>>> cop1 = copy.copy(origin)
>>> cop2 = copy.deepcopy(origin)
>>> cop1 == cop2
True
>>> cop1 is cop2
False 
#cop1 和 cop2 看上去相同，但已不再是同一个object
>>> origin[2][0] = "hey!" 
>>> origin
[1, 2, ['hey!', 4]]
>>> cop1
[1, 2, ['hey!', 4]]
>>> cop2
[1, 2, [3, 4]]
#把origin内的子list [3, 4] 改掉了一个元素，观察 cop1 和 cop2
```
deepcopy貌似就是符合字面的意思：深度拷贝，能够独立出来。那shalow copy和他到底有什么区别？

Python 存储变量的方法与其说是把值赋给变量，不如说是给变量建立了一个到具体值的 reference。

当在 Python 中 a = something 应该理解为给 something 贴上了一个标签 a。当再赋值给 a 的时候，就好象把 a 这个标签从原来的 something 上拿下来，贴到其他对象上，建立新的 reference。 这就解释了一些 Python 中可能遇到的诡异情况：
```
>>> a = [1, 2, 3]
>>> b = a
>>> a = [4, 5, 6] //赋新的值给 a
>>> a
[4, 5, 6]
>>> b
[1, 2, 3]
# a 的值改变后，b 并没有随着 a 变

>>> a = [1, 2, 3]
>>> b = a
>>> a[0], a[1], a[2] = 4, 5, 6 //改变原来 list 中的元素
>>> a
[4, 5, 6]
>>> b
[4, 5, 6]
# a 的值改变后，b 随着 a 变了
```
上面两段代码中，a 的值都发生了变化。区别在于，第一段代码中是直接赋给了 a 新的值（从 [1, 2, 3] 变为 [4, 5, 6]）；而第二段则是把 list 中每个元素分别改变。

而对 b 的影响则是不同的，一个没有让 b 的值发生改变，另一个变了。怎么用上边的道理来解释这个诡异的不同呢？

首次把 [1, 2, 3] 看成一个物品。a = [1, 2, 3] 就相当于给这个物品上贴上 a 这个标签。而 b = a 就是给这个物品又贴上了一个 b 的标签。
![](https://iaman.actor/assets/post05/pythonvariable1.gif)

第一种情况：
a = [4, 5, 6] 就相当于把 a 标签从 [1 ,2, 3] 上撕下来，贴到了 [4, 5, 6] 上。

在这个过程中，[1, 2, 3] 这个物品并没有消失。 b 自始至终都好好的贴在 [1, 2, 3] 上，既然这个 reference 也没有改变过。 b 的值自然不变。
![](https://iaman.actor/assets/post05/pythonvariable2.gif)

第二种情况：
a[0], a[1], a[2] = 4, 5, 6 则是直接改变了 [1, 2, 3] 这个物品本身。把它内部的每一部分都重新改装了一下。内部改装完毕后，[1, 2, 3] 本身变成了 [4, 5, 6]。

而在此过程当中，a 和 b 都没有动，他们还贴在那个物品上。因此自然 a b 的值都变成了 [4, 5, 6]。

![](https://iaman.actor/assets/post05/pythonvariable3.gif)

### 到底发生了什么？
两种 copy 只在面对复杂对象时有区别，所谓复杂对象，是指对象中含其他对象（如复杂的 list 和 class）。

由 shallow copy 建立的新复杂对象中，每个子对象，都只是指向自己在原来本体中对应的子对象。而 deep copy 建立的复杂对象中，存储的则是本体中子对象的 copy，并且会层层如此 copy 到底。

![](https://iaman.actor/assets/post05/shallowcopy.gif)

先看这里的 shallow copy。 如图所示，cop1 就是给当时的 origin 建立了一个镜像。origin 当中的元素指向哪， cop1 中的元素就也指向哪。

这里的关键在于，origin[2]，也就是 [3, 4] 这个 list。根据 shallow copy 的定义，在 cop1[2] 指向的是同一个 list [3, 4]。那么，如果这里我们改变了这个 list，就会导致 origin 和 cop1 同时改变。这就是为什么上边 origin[2][0] = "hey!" 之后，cop1 也随之变成了 [1, 2, ['hey!', 4]]。

![](https://iaman.actor/assets/post05/deepcopy.gif)

再来看 deep copy。 从图中可以看出，cop2 是把 origin 每层都 copy 了一份存储起来。这时候的 origin[2] 和 cop2[2] 虽然值都等于 [3, 4]，但已经不是同一个 list了。

![](https://iaman.actor/assets/post05/deepcopy2.gif)

既然完全独立，那无论如何改变其中一个，另一个自然不会随之改变。

## Share
最近看了看机器学习中的关联规则，就是淘宝京东经常用到的推荐系统，我们需要在交易数据集中挖掘（项）也就是商品的关联规则。

项或项集在交易数据中刚出现的频率称之为支持度

support(X) = #X/n

关联规则X——>Y的置信度为包含X和Y的交易数比上包含X的交易数。

Confidence(X->Y) = #(X U Y)/#(X)
置信度衡量的是关联规则的强度

有一些概念：
频繁项集：支持度超过sigma的项集
强规则：在频繁项集的基础上满足置信度超过phi的规则。
那么如何去寻找关联规则?

step1:找出所有频繁项集（这是关键）

step2：使用频繁项集生成关联规则

但是一个一个列举计算复杂度很高，怎么办？

## ————Apriori算法————
### 如果一个集合是频繁项集，则它的所有子集都是频繁项集
### 如果一个集合不是频繁项集，则它的所有超集都不是频繁项集

```
伪代码
Ck：候选k项集     Lk：频繁k项集
L1<——{frequency items}
for(k =1;Lk != phi; k++)
     Ck+1 <--- candidate(Lk)            候选
   for each transaction t
          Q<---{C属于Ck+1 并且 C是t的真子集}               计数
          给C计数加一
Lk+1 <-----{C属于Ck+1 并且C是频繁项集}                过滤
```

具体应用下周继续。。。
